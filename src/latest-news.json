[{"title":"\"Upcoming Changes for USC Research Computing","image":"/images/slider-image-1-small.jpg","content":"For the first half of 2020, USC Research Computing has been working on many different projects to improve its service quality and the experience for our users. While some of our legacy systems have been experiencing issues recently, the Research Computing team has been working relentlessly to deliver improved high-performance computing systems and services that will change the computing environment, user support and education, and overall business model of USC Research Computing. There are many changes scheduled to be announced during the summer and the fall 2020 semester. Below is a summary of the many exciting changes in the works.\n\n1. **A few improvements that have already been completed:**\n\n•\t /rcf-proj2 & /rcf-proj3: Our old project file system had a stability issue with NSF version 4 and its old Solaris platform, and this was causing frequent system downtime. In order to keep users’ data safe, we had to make the file system read-only in April.\n\n•\t/scratch (800TB): This is a new parallel file system running ZFS/BeeGFS. It was originally planned to be a temporary scratch file system with a data purging policy, but it is now serving as a semi-permanent data storage space until the new /project file system is available.\n\n•\t/staging (230TB): The old staging file system (230TB) was retired in early June, as the storage space wasn’t large enough to keep up with users’ needs. We have since upgraded /staging to another parallel file system called /scratch2.\n\n•\t/scratch2 (700TB): This is another ZFS/BeeGFS parallel file system available as a scratch space. At the moment, the system is available for long-term data storage without a data purging policy. The purging will resume once the new project file system is available and data migration is completed.\n\n•\thpc-transfer upgrade: The old hpc-transfer was decommissioned. A new system is now connected to a faster uplink switch with higher bandwidth (100GE) and low latency. We plan to add a few more data transfer tools, such as GlobusConnect and IBM Aspera.\n\n2. **New cluster: Discovery**\n\nOur new Research Computing cluster, Discovery, will debut in July to serve the USC research community. The new system comes with many changes that will provide better usability and a more sophisticated application layer. Noticeable improvements include:\n\n•\t/home directory: Every user on Discovery will get a 100GB allocation of home directory space. The home directory provides 2-week snapshots with daily backups, so if you accidentally delete some of your important data, you can recover the data if the deletion was within the last three weeks.\n\n•\tRebuilt software stack: We have rebuilt a couple hundred new applications on the cluster, and the new application stack was built with the Lmod/Spack module build system. Users can use available software via module loading, and necessary environment variables and other dependencies associated with libraries, compilers, and MPI stacks are automatically managed. More details and instructions will be available in our new user guides.\n\n•\tMulti-jobs on a single node: The new Slurm policy is now supporting multiple jobs running on a single node. So far, we have used a “single-job on a single-node” policy in order to avoid unexpected system crashes. With a new Slurm configuration, multiple jobs can share one compute node, increasing system efficiency and reducing waiting time in the queue significantly.\n\n3. **New Project file system**\n\nA new, high-performing parallel file system will be deployed this summer. This new storage system will provide 10PB of disk space and will replace the current /rcf-proj file systems. We expect this new file system will out-perform the current project file system with much more room for data. The pricing for this file system has not been finalized, but it will be within a very reasonable range and much more affordable than any of the public cloud storage services.\n\n4. **New Condo Cluster Program (CCP)**\n\nWe will continue to support the condo cluster system, but it will have some changes in its operation model. Rather than operating based on hardware ownership, we will utilize an annual subscription model. Researchers will be able to purchase computing resources (in the number of compute nodes or cores) for their annual needs, and they will be able to adjust the scale of their resources when renewing. The new model provides much more flexibility for users in terms of resource choices, and a much faster setup process without waiting through the entire system purchasing and installation process. The new business model and its new policies have been developed, and the new Condo Cluster Program will be launched in the fall semester of 2020.\n\n5. **New process for resource allocation management**\n\nWe are introducing a new allocation and project management process. It is similar to what we currently use, but with a few major differences:\n\n•\tUsers must be PhD-level researchers (faculty, postdoc, research scientists) to be eligible to be a PI.\n\n•\tEach PI will need to set up a project (or multiple projects) via an online user portal (more details in the next section), and PIs will be able to add/remove users for themselves.\n\n•\tOnce the project is set up, PIs can request resources (either compute nodes or storage space), and each resource should be associated with a PI’s project.\n\n•\tAllocations will have four tiers: small (up to 200K SUs**),* medium (up to 500K SUs), large (up to 1M SUs), and special (more than 1M SUs). Each tier will have a different review & approval process.\n\n\\*SU (System Unit): An hour of a CPU core time on a cluster system.\n\n6. **New website & user portal**\n\nA brand-new website for USC Research Computing will be launched in the summer of 2020. It comes with exciting services including all-new User Guides, an integrated Q&A platform for FAQs and discussions, and online user training and workshop materials. One of the most exciting features of the new website is the built-in user portal that will allows users to see their project information, allocation balance, and the system usage of their projects via a user dashboard. The project and allocation request and management process described in the previous section will be available as self-service features. Detailed information on system utilization and users’ job status will also be available based on each user’s project and allocation status on the system.\n\n7. **Data archiving service**\n\nFor those users who need an extra copy of their data, or even mirrored data archiving at another location (e.g., at Clemson University) for disaster recovery, we will offer a data archiving service for an extra fee. This data archiving service is jointly offered with the USC library and the Shoah Foundation, who is the world-leading expert in digital restoration and data archiving services. The data archiving service will be available from the fall semester of 2020.\n"},{"title":"White House Announces COVID-19 High Performance Computing Consortium","image":"/images/cdc-w9keokhajkw-unsplash.jpg","content":"On March 23, 2020, The White House launched the **COVID-19 High Performance Computing Consortium**, a new program that offers COVID-19 researchers access to high performance computing systems. The use of these systems aims to greatly expedite the timelines for calculations and modeling required for the research of the virus.\n\nCreated by the White House Office of Science and Technology Policy, the US Department of Energy, and IBM, this partnership brings together the public and private sectors to provide resources for research into COVID-19. Consortium members include leaders in industry and academia, as well as federal agencies and the US Department of Energy National Laboratories, all of which have donated free compute time and resources on their high performance computing systems.\n\nDetails about the consortium and statements from its members can be found here: <https://www.whitehouse.gov/briefings-statements/white-house-announces-new-partnership-unleash-u-s-supercomputing-resources-fight-covid-19/>\n\nThe consortium is currently accepting research proposals related to COVID-19 on its online portal. Information on the consortium’s computing resources and instructions for submitting proposals can be found here: <https://covid19-hpc-consortium.org/>\n\nUSC Research Computing is committed to supporting USC researchers in the effort of fighting COVID-19. We are offering our resources for research related to the virus, and we welcome any possible partnerships for proposal submission to the consortium. Researchers in bioinformatics, epidemiology, molecular modeling, and any other relevant areas are invited to contact us at carc-support@usc.edu to find out more about the program.\n"},{"title":"Updates to Project File System Storage Allocations","image":"/images/slider-image-4-small.jpg","content":"With our new project file system comes a change to our storage allocation quota and policy.\n\nStorage allocations are measured using disk space in terabytes (equivalent to 1,000 gigabytes).  \n\nAll active projects automatically receive a storage allocation on the CARC project file system. The default minimum allocation size is 5 TB per project, and each PI receives a maximum allocation of 10 TB for their project(s) at no cost. All users for a project will have access to that project's allocation.\n\nIf more than 10 TB is needed, a PI can request additional storage space through the [Research Computing User Portal](https://hpcaccount.usc.edu/). The additional storage space in excess of the first 10 TB is a paid service. Additional storage space can be added in increments of 5 TB, and the current price is $200/5 TB/year. For example, when a PI requires 20 TB total of space, the annual cost for the data storage space will be:\n\n>20 TB per year = 10 TB free + (2 x $200/5 TB/year) = $400 annual cost\n\nFor more information on allocations, see our [Accounts and Allocations page](https://carc.usc.edu/user-information/accounts)."},{"title":"Exploring New Features on the CARC Website","image":"/images/home-page-small.png","content":"Announced in August 2020, the Center for Advanced Research Computing's new website is a major upgrade to USC's Research Computing program. In addition to its updated design, the website also includes numerous new features not seen on our previous website.\n\n[Home Page Resources](https://carc.usc.edu/)\n\n[](https://carc.usc.edu/)On our home page, you'll find a dashboard-style view of announcements, news stories, Tweets, helpful links, the current CARC system status, and a preview of the latest posts in our Discourse community. Check back frequently to see important announcements, exciting news stories and interviews, and to stay up-to-date on our Twitter and Discourse feeds!\n\n![](/images/columns.png)\n\n[News and Announcements](https://carc.usc.edu/news-and-events/news-and-announcements)\n\nOur news stories include CARC-specific content, including alerts about system maintenance and announcements of new or upgraded services, as well as community interest stories about research being done with CARC resources. In the coming months, we plan to feature interviews with some of our current researchers. Stay tuned!\n\n![](/images/news.png)\n\n[User Support](https://carc.usc.edu/user-support)\n\nOur User Support page is a first-point-of-contact for any and all problems or questions you might have.\n\nHere, you'll find links to our User Guides and Frequently Asked Questions pages to provide solutions for common questions or issues. This is also where you'll access our Ticket Submission page if you require help from a CARC staff member.\n\nWe've also provided links to our User Portal, where Principal Investigators (PIs) can manage their projects and resource allocations, and to our Discourse User Forum, which is a discussion community for CARC users (described below).\n\nIf you're experiencing issues with your USC NetID (which you use to log in to CARC systems) or Duo two-factor authentication, we've also provided a link to USC's IT Services help pages.\n\n![](/images/user-support.png)\n\n[Discourse User Forum](https://hpc-discourse.usc.edu/categories)\n\nThe Discourse discussion platform is a question-and-answer community for CARC users to ask questions, discuss research computing, and share their experiences with CARC systems and resources. It's a great place to seek out collaborative help from other users. CARC staff also post about troubleshooting and solutions to any common or unique issues our users have experienced.\n\n![](/images/discourse.png)"},{"title":"CARC and Researchers Benefit from Reciprocal Partnerships","image":"/images/slider-image-1-small.jpg","content":"USC’s Center for Advanced Research Computing provides advanced computational research systems to the USC community. The CARC goes further than just providing resources, though: it also collaborates closely with the university’s wide variety of research groups, supporting their specialized needs and furthering their research.\n\nThroughout 2020 — and amid a worldwide pandemic — the CARC has continued to develop and strengthen its mutually-beneficial partnerships with USC’s researchers.\n\nThe CARC has a strong partnership with USC’s Information Sciences Institute (ISI), and with Carl Kesselman, Director, Informatics Division, in particular. Earlier this year, the CARC collaborated with Kesselman on a project proposal for a secure hybrid cloud system to support scientific research in Southern California. In August, the proposal was awarded a [$400,000 grant](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2019220&HistoricalAwards=false) from the National Science Foundation’s Campus Cyberinfrastructure program. In addition to this project, the CARC and Kesselman have plans to collaborate on future projects and research grant proposals.\n\nAnother researcher that the CARC has a close working relationship with is Andrew McMahon, founding Chair of the Department of Stem Cell Biology and Regenerative Medicine and Director of the Eli and Edythe Broad Center for Regenerative Medicine and Stem Cell Research at USC’s Keck School of Medicine. Working with large data sets in the range of 50 to 100 terabytes, McMahon’s lab utilizes CARC resources for bioinformatics analysis of next-generation sequencing data, including experiments to monitor protein-DNA interactions using ChIP-seq, a sequencing method combining chromatin immunoprecipitation (ChIP) with massively parallel sequencing.\n\nIvan Bermejo-Moreno, Assistant Professor of Aerospace and Mechanical Engineering at the Viterbi School of Engineering, uses CARC resources in his research of computational fluid mechanics and turbulent fluid flows. Of the CARC, Bermejo-Moreno says, “As a junior faculty working in the area of predictive science and engineering through simulation and numerical diagnostics, my group primarily relies on HPC \\[high-performance computing] resources, both at USC and at the National Laboratories, to advance our research.” In the spring, Bermejo-Moreno and his team had the opportunity to test the CARC’s Discovery cluster before it was released to the general user community, which provided invaluable feedback and quality assurance for the CARC.\n\nThese are only a few examples of the CARC’s commitment to its users and to the larger research community at USC. As its services are expanded and its systems continue to be upgraded, the CARC hopes to also increase its number of partnerships, particularly with academic fields that may not have benefited from research computing previously.\n\nFor more information on partnerships, see our [Research Partnerships page](https://carc.usc.edu/services/research-partnerships) and our [Research Profiles](https://carc.usc.edu/news-and-events/researcher-profiles)."},{"title":"\"Scheduled CARC System Maintenance - September 18, 2020 \"","image":"/images/slider-image-5-small.jpg","content":"On September 18, our systems will undergo full-day maintenance, which will include improving Discovery’s interconnection network performance and installing our new project file system. System downtime will begin at 8:00 am and is projected to finish by the evening.\n\nDuring this time, all CARC systems, including the Discovery cluster, condo nodes, and our file systems, will be unavailable. Your data in our file systems will not be accessible during this time, but it will **not** be erased. The Slurm job scheduler will not be accepting jobs to run during the maintenance period. Once the maintenance is completed, we will send out an announcement.\n\nAfter the maintenance, we will be working with you to complete the data migration process from our current project file system to the new one. You will receive an email from us with instructions on how to migrate your data. Please look out for this email so you can begin your data migration process as soon as possible.\n\nAs always, please make sure that you have backed up any important data.\n\nMoving forward, we plan to have regular system maintenance scheduled for the third Friday of each month; September 18 will be the first occurrence of this regular maintenance."},{"title":"USC's Center for Advanced Research Computing (CARC) Officially Launches","image":"/images/slider-image-2-small.jpg","content":"With the launch of its new high-performance computing cluster, USC’s Center for High-Performance Computing (HPC) has also officially changed its name to the Center for Advanced Research Computing (CARC).\n\nThis new name signifies the research support-focused direction the CARC is heading in. In addition to the new cluster and other system upgrades, the CARC will be expanding their services to include an updated, subscription-based condo node program, as well as a data archiving service. A new website, project resource user portal, and user education program will also be developed to support the research of USC’s faculty and students.\n\nA comprehensive list of the CARC’s system upgrades and upcoming changes can be found here: <https://carc.usc.edu/news-and-events/news-and-announcements/upcoming-changes-summer-fall-2020>\n"},{"title":"December Maintenance and 2020 Winter Recess Schedule","image":"/images/holiday_graphic.jpg","content":"\nAt the end of each year, USC departments cease operations for a winter recess period. This year, the CARC will be closed for the holidays beginning **Monday, December 21, 2020, reopening on Monday, January 4, 2021**. Non-emergency work will be paused until the new year. In the case of an emergency, tickets can still be submitted via our [ticket submission form](/user-information/ticket-submission).\n\nDuring this recess, USC Facilities Management Services will be performing a UPS (Uninterruptable Power Supply) system upgrade in the ITS data center. This upgrade affects all systems that utilize the data center, including CARC systems. The power system upgrade will commence on Sunday, December 27 at 8:00 pm. **All CARC systems, including Discovery, Endeavour, and the file systems, will be down during this maintenance period**. Please plan accordingly so your research work is not impacted. We will keep you updated on this event as we get more details before the winter recess.\n \nA special reservation in Slurm is configured not to take any jobs running past 8:00 pm on December 27. Users on Discovery do not need to worry about the runtime limit for new jobs (48 hours max), but Endeavour condo cluster users should note that new jobs that run longer than 3 weeks will not start until the completion of the upgrade. If you have any questions or concerns about this, please contact us by [submitting a help ticket](/user-information/ticket-submission).\n\nBecause this downtime will depend on the timeline by Facilities Management Services, we cannot guarantee on which day we will bring CARC systems back up. As soon as the upgrade is completed, we will then bring our systems back up, which we anticipate could take ~2 days. **At the latest, we expect to have our systems back up by January 6**. We will send out an announcement once the systems are accessible again. We apologize for such a long period of downtime, but this critical upgrade affects all systems that use the data center, including ours.\n\nFrom everyone at the Center for Advanced Research Computing, we hope you have a safe and warm holiday season. We look forward to continuing to support your research in 2021!\n\n*Please note that a previous version of this story stated that winter recess began on December 25. The winter recess was extended to begin from December 21 by President Folt on December 10.*\n"},{"title":"New Condo Cluster Program Officially Launches","image":"/images/slider-image-2-small.jpg","content":"\nThe CARC is pleased to announce its new [Condo Cluster Program (CCP)](/user-information/ccp/program-information), offering greater flexibility for researchers who prefer to have access to their own dedicated compute nodes.\n\nPrior to the development of the new CCP, PIs could purchase dedicated compute nodes using a traditional purchase model, which specified a five-year service term for the chosen nodes, after which the nodes would be retired. This pricing model remains, but the CCP also now includes an annual subscription pricing model. PIs can subscribe to their desired nodes on an annual basis, choosing either to renew, modify, or terminate their subscription each year. In both models, PIs have access to nodes that are completely dedicated for their own jobs, without the job limits and resource restrictions that the nodes in the general-use Discovery cluster have.\n\nPurchases and subscriptions can now be requested and managed in the [CARC user portal](/user-information/user-guides/research-computing-user-portal), much like Discovery and storage allocations. Subscriptions are requested in the same way as Discovery and storage allocations (see the [Request New Allocation user guide](/user-information/user-guides/research-computing-user-portal/request-new-allocation) for instructions). Purchases are requested via a new purchase form on the [Condo Purchase Requests page](https://hpcaccount.usc.edu/purchase/), under the “Project” tab (see the [Request New Condo Purchase user guide](/user-information/user-guides/research-computing-user-portal/request-new-purchase) for instructions).\n\nNodes subscribed to or purchased through the CCP form the [Endeavour condo cluster](/user-information/user-guides/high-performance-computing/getting-started-endeavour), which is a new high-performance computing cluster designated especially for the CCP. CCP users will enjoy the same advanced computing capabilities, fast speeds, and software stack that the Discovery cluster offers.\n\n**More information**\n\n* [Condo Cluster Program pages](/user-information/ccp)\n* [Subscription Pricing Model](/user-information/ccp/program-information/ccp-subscription)\n* [Purchase Pricing Model](/user-information/ccp/program-information/ccp-purchase)\n* [Getting Started with the Endeavour Condo Cluster user guide](/user-information/user-guides/high-performance-computing/getting-started-endeavour)\n* [Request New Condo Purchase user guide](/user-information/user-guides/research-computing-user-portal/request-new-purchase)\n\n"},{"title":"HackSC Connects the World in 2021","image":"/images/hacksc.jpg","content":"\n*The Center for Advanced Research Computing is a proud sponsor of HackSC ‘21.*\n\nUSC’s largest student-run hackathon, HackSC, is back for 2021 with a new virtual format. \n\n**What’s a hackathon?** From HackSC’s website: “A hackathon is a 36 hour competition in which teams of students collaborate to ideate and innovate solutions to real world problems!\"\n\nHackSC ‘21 runs for 36 hours from February 19-21, and Katie Wong (President), Elissa Perdue (Vice President and Director of Sponsorship), and Max Leiter (Vice President and Lead of Engineering) are united in their vision of making HackSC rise to become one of the best hackathons in the nation.\n\nThis year, HackSC is operating with a theme of **connectivity** with the goal of connecting the world. The theme is clearly the result of the ongoing COVID-19 pandemic and social distancing becoming the “new normal”. “We got launched into this pandemic and had just been coming off of our [last] hackathon in 2020,” says Wong. “We were faced with the decision of ‘what should we do moving forward?’. We realized hackathons [are] incredibly important for [students’] innovation. With that, we wanted to continue the spirit of hackathons and allow students to continue to innovate and collaborate with other people.”\n\nThe choice to move forward with an online format for HackSC ‘21 was an obvious — and early — one for the executive team. “We chose to go online really early because we saw that it might be necessary,” says Leiter. A year after the onset of the pandemic, the choice to move online for 2021 is proving to be a smart one.\n\nHackSC is combating the feelings of isolation that could arise with an entirely online hackathon by creating their own in-house application. Without the usual in-person meeting and mingling, participants might find it challenging to link up with their peers and form teams. HackSC’s solution was to build a team-matching portal to group participants into teams. They also plan to use the portal to promote interaction by grouping people together for one-on-one coffee chats. “We wanted to make sure our hackathon allows hackers to not only collaborate on projects, but also meet new people and participate in fun activities so they continue to feel like they’re a part of this hackathon,” says Wong.\n\nHackathons aren’t just for students with computer science and engineering backgrounds. HackSC is open to undergraduate and graduate students from all majors, and students with no coding experience are encouraged to participate and share their ideas. “[A hackathon] is a really cool space to bring together a lot of ideas and backgrounds [...] coming together and bringing different perspectives,” says Perdue.\n\nStudents in non-STEM majors might be apprehensive to participate in a hackathon, but the do-it-yourself nature of a hackathon is the perfect opportunity for students to try something outside their comfort zones. “When I started going to hackathons, I was very self conscious about my abilities and wasn’t sure if I would be able to make anything,” says Wong, who has now attended numerous hackathons throughout California. “When you’re creating a completely new product, you get the chance to fail. You get the chance to try new things and learn new technologies.”\n\nBesides the opportunity to get involved with their peers at USC, for Wong, Perdue, and Leiter, hackathons are a great way to learn new technologies that are being used in the industry. Often, the programming languages and technologies used in Computer Science classrooms aren’t necessarily what’s currently popular. “Hackathons and their workshops and speakers give you a chance to see what technologies are used in the field. The companies that sponsor us are modern, current companies that are usually pretty popular,” says Leiter. This year’s sponsors include InterSystems, Northrop Grumman, and Google Cloud, among others.\n\nAbove all, HackSC ‘21 serves as a way for USC students to stay connected during a challenging time. Wong, Perdue, and Leiter hope that this year’s hackathon can produce projects that help bring the world closer together: “We really wanted to create a space for hackers to innovate on connectivity and create projects that are going to connect people in this new age we’re moving into.”\n\n*For more information about HackSC ‘21, see their website at https://hacksc.com.*"},{"title":"News","image":"/images/class-2020.png","content":"No content given"},{"title":"Spring 2021 CARC Workshops Cover New Topics","image":"/images/slider-image-books-small.jpg","content":"\nThe Center for Advanced Research Computing is excited to announce its Spring 2021 workshop schedule!\n\nThis semester, we're focusing on new topics that are of the most interest and use for our users. Thank you to those users who participated in our workshop survey a few weeks ago. The feedback we received was very helpful for choosing workshop formats, times, and topics. We plan to send out another survey at the end of the semester to get your feedback on the Spring 2021 workshops.\n\nWe'll be offering workshops virtually **every Friday from 1-3 pm PST**, with the exception of the third Friday of each month, which is typically reserved for system maintenance. \n\n<a href=\"/news-and-events/events\" class=\"markdown-custom-link\">Workshop Registration</a>\n\n### Weekly workshop schedule\n\n#### Introduction to CARC Systems: Friday, February 5, 2021\n\nAn overview of the CARC's high-performance computing clusters. This workshop covers how to log in, manage and transfer data, load and build software, and run and monitor jobs.\n\n#### Introduction to R: Friday, February 12, 2021\n\nAn introduction to the R programming environment and language for statistical computing and graphics. This workshop covers basic R concepts and functions for importing, exporting, processing, summarizing, visualizing, and modeling data. It also covers how to install packages and develop scripts and discusses best practices for R programming.\n\n#### Software Management on CARC Systems: Friday, February 26, 2021\n\nThis workshop introduces users to the CARC's software stack, which uses Lmod, a Lua-based module system. Users will learn how to manage their environment, find software, load modules, and build their own domain-specific packages.\n\n#### HPC with R: Friday, March 5, 2021\n\nIntermediate-to-advanced topics in R programming using the CARC's high-performance computing clusters, including data I/O, memory usage, parallel programming, debugging, and profiling.\n\n#### Slurm Job Management: Friday, March 12, 2021\n\nThis workshop covers how to run and monitor jobs using the Slurm workload manager and job scheduler, including topics like requesting resources, evaluating resource use, running MPI jobs and job arrays, and setting up job dependencies.\n\n#### HPC with Python: Friday, March 26, 2021\n\nIntermediate-to-advanced topics for getting improved Python performance in an HPC cluster environment. Covers debugging, profiling, and parallel programming.\n\n#### Data Management on CARC Systems: Friday, April 2, 2021\n\nThis workshop covers various topics in data management and transfer on CARC systems, including transfer tools, file permissions, file I/O, and backups.\n\n#### Software Containers with Singularity: Friday, April 9, 2021\n\nAn overview of software containers and how to use Singularity to create and run containers for research and high-performance computing tasks. Singularity containers enable portable and reproducible computing environments and workflows. Build a container with a desired software environment and you can run it on personal or workstation computers, on the CARC's high-performance computing clusters, and in the cloud.\n\n#### Methods for Automating Job Submission: Friday, April 23, 2021\n\nCARC users may find themselves doing repetitive tasks like manually launching jobs, checking their job status, and deciding what kind of jobs to submit based on the results. This workshop covers methods for automating these tasks with tools like job arrays and workflow management software.\n\n### Semester-long workshops\n\nIn addition to our weekly workshops, we're offering two semester-long workshops: **CP2K: Running Ab Initio Molecular Dynamics Simulations** and the **Vienna Ab initio Simulation Package (VASP) series**. These practical, hands-on sessions build on the skills learned each week, but users can still drop in at any point during the semester to see what's being taught. Full descriptions of these workshops can be found on our [Seminars and Workshops page](/education-and-outreach/seminars-and-workshops), and registration details are on our [Events page](/news-and-events/events).\n"}]